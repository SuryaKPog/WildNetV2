# -*- coding: utf-8 -*-
"""DL PROJECT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14JX9iq2UWZEAJpOdPi86drufHa_RT4-c

# **Animal Image Classification Using Deep Learning**

This notebook trains a deep learning model to classify images of animals. We will follow a structured approach:


Install & Import Dependencies

Unzip & Load the Dataset

Explore the Data

Data Preprocessing & Augmentation

Build the CNN Model

Train the Model

Evaluate Model Performance

Test on the Validation Set

Save the Model

Test on New Images

Future Improvements



**Preprocess the data â€“ Resize images, normalize pixel values**

**Define the model â€“ CNN (Convolutional Neural Network)**

**Train the model â€“ Using TensorFlow/Keras**

**Evaluate performance â€“ Accuracy, loss, confusion matrix**

**Make predictions â€“ Test on sample images**

#Step 1: Install & Import Dependencies

Before starting, we need to import necessary libraries for deep learning, image processing, and visualization.
"""

import os
import numpy as np
import random
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import SGD

"""# Step 2: Unzip & Load the Dataset

We extract the dataset from the ZIP file and organize image paths.
"""

import zipfile

# Define the uploaded file name
zip_path = "/content/animaldata.zip"  # Ensure this matches your uploaded file

# Extract the ZIP file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall("/content/animaldata")

# Define dataset paths
dataset_dir = "/content/animaldata/animals/animals"
labels_file = "/content/animaldata/nameanimals.txt"

# Read class labels
with open(labels_file, 'r') as f:
    class_labels = [line.strip() for line in f.readlines()]

print("Classes:", class_labels)



from google.colab import drive

# Unmount Google Drive
drive.flush_and_unmount()

print("Google Drive has been disconnected.")

"""# Step 3: Load and Explore the Data

Load and visualize some images to understand the dataset.

Collect All Image Paths from Subfolders
"""

import os
import random
import cv2
import matplotlib.pyplot as plt

# Path to the main dataset folder
dataset_dir = "/content/animaldata/animals/animals"

# Collect all image paths
image_files = []
for animal in os.listdir(dataset_dir):  # Loop through each animal folder
    animal_path = os.path.join(dataset_dir, animal)
    if os.path.isdir(animal_path):  # Check if it's a folder
        for img in os.listdir(animal_path):
            if img.lower().endswith(('.jpg', '.jpeg', '.png')):  # Filter images
                image_files.append(os.path.join(animal_path, img))

# Check if images are available
if len(image_files) == 0:
    print("No images found in the dataset directory.")
else:
    print(f"Found {len(image_files)} images in {len(os.listdir(dataset_dir))} categories.")

    # Display 5 random images
    plt.figure(figsize=(10, 5))
    for i in range(min(5, len(image_files))):  # Handle cases where <5 images exist
        img_path = random.choice(image_files)
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB

        plt.subplot(1, 5, i+1)
        plt.imshow(img)
        plt.title(img_path.split("/")[-2])  # Show category name
        plt.axis("off")

    plt.show()



"""# Step 4: Data Preprocessing & Augmentation

We'll use ImageDataGenerator to:

Rescale pixel values to [0,1]

Apply data augmentation (rotation, zoom, flipping, etc.) to prevent overfitting
"""

tf.keras.mixed_precision.set_global_policy('mixed_float16')

# âœ… Optimized Image Size
IMG_SIZE = (240, 240)
BATCH_SIZE = 32
NUM_CLASSES = 90

# âœ… Optimized Data Augmentation
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.3,
    horizontal_flip=True,
    validation_split=0.2
)

# âœ… Load Dataset
dataset_dir = "/content/animaldata/animals/animals"

train_generator = train_datagen.flow_from_directory(
    dataset_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="sparse",
    subset="training"
)

val_generator = train_datagen.flow_from_directory(
    dataset_dir,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="sparse",
    subset="validation"
)



"""# Step 5: Build the CNN Model

We'll define a CNN architecture with:

3 convolutional layers for feature extraction

MaxPooling layers for dimensionality reduction

Dropout for regularization

Fully connected layers for classification
"""

# Define CNN Model
model = Sequential([
    Input(shape=(150, 150, 3)),  # Input layer with image shape

    Conv2D(32, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(128, (3,3), activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(512, activation='relu'),
    Dropout(0.5),  # Prevent overfitting
    Dense(NUM_CLASSES, activation='softmax')  # Output layer
])

from tensorflow.keras.optimizers import Adam

model.compile(optimizer=Adam(learning_rate=0.001), loss="categorical_crossentropy", metrics=["accuracy"])

model.summary()



"""# Step 6: Load Pretrained Model EfficientNet80

We initially implemented a Convolutional Neural Network (CNN) from scratch, but the results were not very promising:

Low Accuracy (~20%) even after multiple epochs
Slow Convergence â€“ learning was very slow
Overfitting Issues â€“ validation accuracy was not improving significantly
ðŸš€ Why Switch to MobileNetV2?
Given the challenges with CNN, we decided to use MobileNetV2, a pretrained deep learning model optimized for image classification. It provides:
âœ… Higher accuracy due to transfer learning from ImageNet
âœ… Faster training as it already knows general image features
âœ… Less overfitting since it's trained on a large dataset


While MobileNetV2 improved performance(~50%), we wanted to further enhance accuracy and efficiency.

EfficientNetB0 offers:

âœ… Better Accuracy â€“ Uses Neural Architecture Search (NAS) to optimize model performance.
âœ… Efficient Training â€“ Balances model size, accuracy, and speed.
âœ… Better Generalization â€“ Handles overfitting better than traditional CNNs.
"""

# âœ… Load Pretrained MobileNetV2
base_model = MobileNetV2(weights="imagenet", include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))
base_model.trainable = False  # Freeze the base model

# âœ… Build Model
model = Sequential([
    base_model,
    GlobalAveragePooling2D(),
    BatchNormalization(),
    Dropout(0.4),
    Dense(512, activation="relu"),
    BatchNormalization(),
    Dropout(0.3),
    Dense(NUM_CLASSES, activation="softmax", dtype="float32")  # Ensure correct dtype for mixed precision
])

# âœ… Optimized Optimizer (Adam with LR scheduling)
optimizer = Adam(learning_rate=0.001)

model.compile(
    optimizer=optimizer,
    loss="sparse_categorical_crossentropy",
    metrics=["accuracy"]
)

#Model Summary
model.summary()

""" # Step 7: Train the Model"""

EPOCHS = 20

history = model.fit(
    train_generator,
    validation_data=val_generator,
    epochs=EPOCHS
)

"""# Step 8: Make Predictions on Samples"""

import numpy as np
from tensorflow.keras.preprocessing import image

# Function to preprocess an image
def preprocess_image(img_path):
    img = image.load_img(img_path, target_size=(240, 240))  # Resize to match input shape
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension
    img_array = img_array / 255.0  # Normalize pixel values
    return img_array

# Path to test image
test_image_path = "sample_test.jpg"

# Preprocess image
img_array = preprocess_image(test_image_path)

# Make a prediction
predictions = model.predict(img_array)

# Get the class with highest probability
predicted_class = np.argmax(predictions)

print(f"Predicted Class: {predicted_class}")

"""it shows index, we need to get label"""

# Load training data to get class labels
train_generator = train_datagen.flow_from_directory(
    "/content/animaldata/animals/animals",  # Replace with actual path
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="sparse",
    subset="training"
)

# Get class indices (dictionary mapping)
class_indices = train_generator.class_indices  # Example: {'cat': 0, 'dog': 1, 'elephant': 2, ...}
class_labels = {v: k for k, v in class_indices.items()}  # Reverse mapping: {0: 'cat', 1: 'dog', 2: 'elephant', ...}

# Print to check if mapping is correct
print(class_labels)

predictions = model.predict(img_array)

# Get the class index with the highest probability
predicted_class_index = np.argmax(predictions)

# Get class name from index
predicted_label = class_labels.get(predicted_class_index, "Unknown")

print(f"Predicted Class: {predicted_label}")

"""#Step 9: Evaluate on the Test Dataset"""

test_generator = train_datagen.flow_from_directory(
    "/content/animaldata/animals/animals",
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode="sparse",
    shuffle=False
)

test_loss, test_accuracy = model.evaluate(test_generator)
print(f"Test Accuracy: {test_accuracy:.4f}")
print(f"Test Loss: {test_loss:.4f}")

model.save("animal_classification_model.h5")  # Save as an H5 file
print("Model saved successfully!")

""" # Step 10: Record the Metrics"""

import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report

# Predict on test data
y_true = test_generator.classes  # Actual labels
y_pred = np.argmax(model.predict(test_generator), axis=1)  # Predicted labels

# Generate confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred)

# Plot it
plt.figure(figsize=(10, 8))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

"""# Step 11: Hyperparameter Tuning & Regularization"""

from tensorflow.keras.layers import Dropout

# Example: Add dropout after a Dense layer
model.add(Dropout(0.5))  # 50% dropout

"""# Step 12: Conclusion & Future Work

**âœ”ï¸ What Worked Well?**

The MobileNetV2 model performed well, achieving a validation accuracy of ~90%, which is good for an animal classification task.

Training was relatively fast due to mixed precision and the optimized 240Ã—240 image size.

The model was able to generalize well across most animal classes.

The accuracy improved significantly after a few epochs, showing that the model effectively learned meaningful features.

**âŒ Where Did the Model Struggle?**

The model struggled with visually similar species (e.g., different breeds of dogs or birds).

Some misclassifications happened due to insufficient training data for certain classes.

Validation accuracy plateaued in later epochs, suggesting overfitting or the need for additional fine-tuning.

The loss did not decrease significantly after a certain point, which could mean the optimizer or learning rate might need adjustment.

**ðŸ”¥ How Can We Improve It?**

Collect More Data ðŸ“Š

Increase dataset size, especially for underrepresented animal classes.
Use data augmentation (rotation, flipping, brightness adjustment) to artificially increase the dataset.

Try a More Powerful Model

EfficientNetB3/B4 or ResNet50/101 may improve accuracy with better feature extraction.
If speed is a concern, MobileNetV3 might offer a good balance.

Hyperparameter Tuning

Experiment with learning rate scheduling (reduce LR when accuracy stops improving).

Fine-tune MobileNetV2 More

Freeze fewer layers and train deeper parts of the network for better feature extraction.

Regularization Techniques

Use Dropout layers to reduce overfitting.

Add L2 regularization to the dense layers.

# Step 13: Publish & Submit Your Work
"""

!jupyter nbconvert --to html your_notebook.ipynb